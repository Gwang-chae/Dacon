{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LG_System_Quality_Change_Prediction(modeling).ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["Ep5IVkRbSgcS","3kkbVo12T8la","XNEyrK0_T00w","Bp-y6GgDUBxS","XD6_lKXETtRi","Ws4ce_x-U8eX","VG87TVG9cw7E","jU8b3mfKgTBV","Z7rkkSJMGBza","3Gt8JObFjynG","5Ymx57IEt2-2","n-YYqRYx-6qG","9XyG5jxB--hG"],"machine_shape":"hm","mount_file_id":"1b7hWl0-z-CwViz7ZUHWqmY4obBnaj3rp","authorship_tag":"ABX9TyPvhQdxDcgLB4s38u3hBuGz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Ep5IVkRbSgcS"},"source":["## Data load and Module mount"]},{"cell_type":"code","metadata":{"id":"oYYu7APkKwqj"},"source":["# from bayes_opt import BayesianOptimization\r\n","from sklearn.preprocessing import MinMaxScaler\r\n","from sklearn.metrics import roc_auc_score, make_scorer\r\n","from sklearn.model_selection import GridSearchCV, train_test_split, cross_validate\r\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\r\n","from tensorflow.keras.layers import BatchNormalization, Dense, Dropout, PReLU\r\n","from tensorflow.keras.metrics import AUC\r\n","from tensorflow.keras.models import Sequential\r\n","from tensorflow.keras.optimizers import Adam\r\n","from tqdm import tqdm\r\n","\r\n","import lightgbm as lgbm\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","import pandas as pd\r\n","import re\r\n","import scipy.stats as stats\r\n","import seaborn as sns\r\n","import tensorflow as tf\r\n","\r\n","\r\n","# train data load\r\n","train_err = pd.read_csv('/content/drive/MyDrive/Colab/data/LG/train_err_data.csv')\r\n","train_quality = pd.read_csv('/content/drive/MyDrive/Colab/data/LG/train_quality_data.csv')\r\n","train_problem = pd.read_csv('/content/drive/MyDrive/Colab/data/LG/train_problem_data.csv')\r\n","\r\n","# test data load\r\n","test_err = pd.read_csv('/content/drive/MyDrive/Colab/data/LG/test_err_data.csv')\r\n","test_quality = pd.read_csv('/content/drive/MyDrive/Colab/data/LG/test_quality_data.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3kkbVo12T8la"},"source":["## Preprocessing"]},{"cell_type":"code","metadata":{"id":"PUoOMDPNK2vX"},"source":["# 16554663개 중에 1개 행렬이므로 해당 행 제거\r\n","# train_err = train_err.dropna()\r\n","\r\n","# 혹은 바로 다음 행과 컬럼 배열이 동일하므로 40013으로 대체\r\n","train_err = train_err.fillna(40013)\r\n","\r\n","# test_err의 na개수는 4 -> drop\r\n","test_err = test_err.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3y-eOeWLGT8"},"source":["# string형태를 int로 바꿀 함수 정의\r\n","def string2num(x):\r\n","    # (,)( )과 같은 불필요한 데이터 정제\r\n","    x = re.sub(r\"[^0-9]+\", '', str(x))\r\n","    if x =='':\r\n","        pass\r\n","    else:\r\n","        return int(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I-mQGgn5Scn1"},"source":["def make_datetime(x):\r\n","    # string 타입의 Time column에서 월일을 추출\r\n","    x     = str(x)\r\n","    month = x[4:6]\r\n","    day   = x[6:8]\r\n","    return int(month + day)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z6F3Wv0lS4rV"},"source":["# month_day라는 새로운 컬럼 생성\r\n","train_err['month_day'] = train_err['time'].apply(make_datetime)\r\n","test_err['month_day'] = test_err['time'].apply(make_datetime)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s-qpBD6vLLAs"},"source":["# ','등 불필요한 문자열이 들어가 있어 object로 읽히던 컬럼들을 string2num 함수를 통해 int 형태로 변환\r\n","\r\n","for i in tqdm(range(13)):\r\n","    quality = 'quality_' + str(i)\r\n","    train_quality[quality] = train_quality[quality].apply(string2num)\r\n","\r\n","for i in tqdm(range(13)):\r\n","    quality = 'quality_' + str(i)\r\n","    test_quality[quality] = test_quality[quality].apply(string2num)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WiHYrPKmLNPm"},"source":["# object 형태인 fwver은 최빈값으로 대체\r\n","# int 또는 float 형태인 quality_0, quality_1, quality_2는 평균값으로 결측값 대체\r\n","\r\n","train_quality['fwver'] = train_quality['fwver'].fillna(train_quality['fwver'].mode()[0])\r\n","train_quality['quality_0'] = train_quality['quality_0'].fillna(train_quality['quality_0'].mean())\r\n","train_quality['quality_1'] = train_quality['quality_1'].fillna(train_quality['quality_1'].mean())\r\n","train_quality['quality_2'] = train_quality['quality_2'].fillna(train_quality['quality_2'].mean())\r\n","train_quality['quality_5'] = train_quality['quality_5'].fillna(train_quality['quality_5'].mean())\r\n","\r\n","# # object 형태인 fwver은 최빈값으로\r\n","# # int 또는 float 형태인 quality_0, quality_1, quality_2, ... 는 평균값으로 결측값 대체\r\n","\r\n","test_quality['fwver'] = test_quality['fwver'].fillna(test_quality['fwver'].mode()[0])\r\n","test_quality['quality_0'] = test_quality['quality_0'].fillna(test_quality['quality_0'].mean())\r\n","test_quality['quality_1'] = test_quality['quality_1'].fillna(test_quality['quality_1'].mean())\r\n","test_quality['quality_2'] = test_quality['quality_2'].fillna(test_quality['quality_2'].mean())\r\n","test_quality['quality_5'] = test_quality['quality_5'].fillna(test_quality['quality_5'].mean())\r\n","test_quality['quality_6'] = test_quality['quality_6'].fillna(test_quality['quality_6'].mean())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oz9UgmEbU1Y6"},"source":["train_err['fwver'] = train_err['fwver'].apply(string2num)\r\n","test_err['fwver'] = test_err['fwver'].apply(string2num)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XNEyrK0_T00w"},"source":["## Errtype count"]},{"cell_type":"code","metadata":{"id":"NqJPuH7eLYao"},"source":["# 데이콘 베이스라인 Modeling\r\n","# errtype counts를 변수로 problem에서 \r\n","# 한 번이라도 user_id가 나오면 오류가 발생했다고 설정\r\n","\r\n","train_user_id_max = 24999\r\n","train_user_id_min = 10000\r\n","train_user_number = 15000\r\n","\r\n","id_error = train_err[['user_id','errtype']].values\r\n","error = np.zeros((train_user_number,41))\r\n","\r\n","for person_idx, err in tqdm(id_error):\r\n","    if err >= 30:\r\n","        error[person_idx - train_user_id_min,err - 2] += 1\r\n","    # person_idx - train_user_id_min 위치에 person_idx, errtype에 해당하는 error값을 +1\r\n","    else:\r\n","        error[person_idx - train_user_id_min,err - 1] += 1\r\n","print(error.shape)\r\n","\r\n","# error와 동일한 방법으로 person_idx - 10000 위치에 \r\n","# person_idx의 problem이 한 번이라도 발생했다면 1\r\n","# 없다면 0\r\n","problem = np.zeros(15000)\r\n","problem[train_problem.user_id.unique()-10000] = 1 \r\n","print(problem.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ovwHzVAcSGo9"},"source":["test_user_id_max = 44998\r\n","test_user_id_min = 30000\r\n","test_user_number = 14999\r\n","\r\n","id_error = test_err[['user_id','errtype']].values\r\n","test_x = np.zeros((test_user_number,41))\r\n","for person_idx, err in tqdm(id_error):\r\n","    # person_idx - test_user_id_min 위치에 person_idx, errtype에 해당하는 error값을 +1\r\n","    if err >= 30:\r\n","        test_x[person_idx - test_user_id_min,err - 2] += 1\r\n","    # person_idx - train_user_id_min 위치에 person_idx, errtype에 해당하는 error값을 +1\r\n","    else:\r\n","        test_x[person_idx - test_user_id_min,err - 1] += 1\r\n","\r\n","print(test_x.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bp-y6GgDUBxS"},"source":["## Quality count"]},{"cell_type":"code","metadata":{"id":"mtGNzCH9LeF0"},"source":["# train_quality 데이터 또한 위와 동일한 방법으로 처리\r\n","# 단, quality값의 총합을 변수로 생성\r\n","\r\n","id_quality = train_quality[['user_id','quality_0','quality_1','quality_2','quality_5','quality_6',\r\n","                            'quality_7','quality_8','quality_9','quality_10','quality_11','quality_12']].values\r\n","\r\n","quality = np.zeros((train_user_number,11))\r\n","\r\n","# ffill등의 방식으로 결측치를 처리하면 float64형태인 컬럼으로 인해 \r\n","# id_quality 또한 float64형태로 바뀌면서 인덱싱에 문제가 생김\r\n","# 따라서, person_idx에 int()를 씌워주면서 값 대입\r\n","\r\n","for person_idx, q0, q1, q2, q5, q6, q7, q8, q9, q10, q11, q12 in tqdm(id_quality):\r\n","\r\n","    # person_idx - train_user_id_min 위치에 person_idx, errtype에 해당하는 error값을 +1\r\n","    if q0 != 0 :\r\n","        quality[int(person_idx) - train_user_id_min, 0] += q0\r\n","    if q1 != 0 :\r\n","        quality[int(person_idx) - train_user_id_min, 1] += q1\r\n","    if q2 != 0 :\r\n","        quality[int(person_idx) - train_user_id_min, 2] += q2\r\n","    if q5 != 0 :\r\n","        quality[int(person_idx) - train_user_id_min, 3] += q5\r\n","    if q6 != 0 :\r\n","        quality[int(person_idx) - train_user_id_min, 4] += q6\r\n","    if q7 != 0 :\r\n","        quality[int(person_idx) - train_user_id_min, 5] += q7\r\n","    if q8 != 0 :\r\n","        quality[int(person_idx) - train_user_id_min, 6] += q8\r\n","    if q9 != 0 :\r\n","        quality[int(person_idx) - train_user_id_min, 7] += q9\r\n","    if q10 != 0 :\r\n","        quality[int(person_idx) - train_user_id_min, 8] += q10\r\n","    if q11 != 0 :\r\n","        quality[int(person_idx) - train_user_id_min, 9] += q11\r\n","    if q12 != 0 :\r\n","        quality[int(person_idx) - train_user_id_min, 10] += q12"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j7zzjZMCSM5P"},"source":["# test_quality 처리\r\n","# trainset에서 행한 방식과 동일하게 train_quality 처리\r\n","\r\n","id_quality = test_quality[['user_id','quality_0','quality_1','quality_2','quality_5','quality_6','quality_7','quality_8','quality_9','quality_10','quality_11','quality_12']].values\r\n","quality_test = np.zeros((test_user_number,11))\r\n","\r\n","for person_idx, q0, q1, q2, q5, q6, q7, q8, q9, q10, q11,q12 in tqdm(id_quality):\r\n","    # person_idx - test_user_id_min 위치에 person_idx, errtype에 해당하는 error값을 +1\r\n","    if q0 != 0 :\r\n","        quality_test[int(person_idx) - test_user_id_min, 0] += q0\r\n","    if q1 != 0 :\r\n","        quality_test[int(person_idx) - test_user_id_min, 1] += q1\r\n","    if q2 != 0 :\r\n","        quality_test[int(person_idx) - test_user_id_min, 2] += q2\r\n","    if q5 != 0 :\r\n","        quality_test[int(person_idx) - test_user_id_min, 3] += q5\r\n","    if q6 != 0 :\r\n","        quality_test[int(person_idx) - test_user_id_min, 4] += q6\r\n","    if q7 != 0 :\r\n","        quality_test[int(person_idx) - test_user_id_min, 5] += q7\r\n","    if q8 != 0 :\r\n","        quality_test[int(person_idx) - test_user_id_min, 6] += q8\r\n","    if q9 != 0 :\r\n","        quality_test[int(person_idx) - test_user_id_min, 7] += q9\r\n","    if q10 != 0 :\r\n","        quality_test[int(person_idx) - test_user_id_min, 8] += q10\r\n","    if q11 != 0 :\r\n","        quality_test[int(person_idx) - test_user_id_min, 9] += q11\r\n","    if q12 != 0 :\r\n","        quality_test[int(person_idx) - test_user_id_min, 10] += q12"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XD6_lKXETtRi"},"source":["## Date count"]},{"cell_type":"code","metadata":{"id":"vYc-s02WLZyL"},"source":["# train_err의 Date count\r\n","id_error = train_err[['user_id','month_day']].values\r\n","order = train_err['month_day'].unique()\r\n","order.sort()\r\n","month_day = np.zeros((train_user_number,len(order)))\r\n","\r\n","for person_idx, mon_day in tqdm(id_error):\r\n","    month_day[person_idx - train_user_id_min, np.where(order == mon_day)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P8fIEvEkR6YM"},"source":["# test_err의 Date count\r\n","# test_err는 train_err 이후의 일주일(7일) 데이터가 일부 있음\r\n","id_error = test_err[['user_id','month_day']].values\r\n","order = test_err['month_day'].unique()\r\n","order.sort()\r\n","month_day_test = np.zeros((test_user_number,len(order)))\r\n","\r\n","for person_idx, mon_day in tqdm(id_error):\r\n","    month_day_test[person_idx - test_user_id_min, np.where(order == mon_day)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MYXnpkJjR6bh"},"source":["test_date_df = pd.DataFrame(month_day_test)\r\n","# test_date = test_date_df.iloc[:,:33]\r\n","# test_date"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qjsjESuJQRYY"},"source":["# test_date_df[32] = test_date_df[33] + test_date_df[34] + test_date_df[35] + test_date_df[36] + test_date_df[37] + test_date_df[38]\r\n","test_date = test_date_df.iloc[:,:33]\r\n","test_date"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ws4ce_x-U8eX"},"source":["## Fwver count"]},{"cell_type":"code","metadata":{"id":"4nD_Z8h_LzfN"},"source":["train_err_fwv = train_err['fwver'].unique()\r\n","test_err_fwv = test_err['fwver'].unique()\r\n","\r\n","# train_err와 test_err의 fwver 중 공통 부분만 추출\r\n","intersec_err_fwv = np.array([x for x in test_err_fwv if x in train_err_fwv])\r\n","\r\n","print(len(train_err_fwv))\r\n","print(len(test_err_fwv))\r\n","print(len(intersec_err_fwv))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5chQAojy1rxr"},"source":["# 추출한 공통 부분에 해당하는 행들을 따로 추출\r\n","train_err_drop = train_err[train_err['fwver'].isin(intersec_err_fwv)]\r\n","test_err_drop = test_err[test_err['fwver'].isin(intersec_err_fwv)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VzkN-oH7TL7m"},"source":["# 공통 부분에 해당하지 않는 행들의 fwver은\r\n","# 기타로 취급하여 999999로 설정\r\n","train_err_etc = train_err[~train_err['fwver'].isin(intersec_err_fwv)]\r\n","test_err_etc = test_err[~test_err['fwver'].isin(intersec_err_fwv)]\r\n","\r\n","train_err_etc['fwver'] = 999999\r\n","test_err_etc['fwver'] = 999999\r\n","\r\n","# train_err의 fwv값을 count\r\n","id_error = train_err_etc[['user_id','fwver']].values\r\n","order = train_err_etc['fwver'].unique()\r\n","order.sort()\r\n","fwv_etc_lst = np.zeros((train_user_number,len(order)))\r\n","\r\n","for person_idx, fwv in tqdm(id_error):\r\n","    fwv_etc_lst[person_idx - train_user_id_min, np.where(order == fwv)[0][0]] += 1\r\n","\r\n","id_error = test_err_etc[['user_id','fwver']].values\r\n","order = test_err_etc['fwver'].unique()\r\n","order.sort()\r\n","fwv_etc_test_lst = np.zeros((test_user_number,len(order)))\r\n","\r\n","for person_idx, fwv in tqdm(id_error):\r\n","    fwv_etc_test_lst[person_idx - test_user_id_min, np.where(order == fwv)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fFiO5brRQFUQ"},"source":["# train_err의 fwv값을 count\r\n","id_error = train_err_drop[['user_id','fwver']].values\r\n","order = train_err_drop['fwver'].unique()\r\n","order.sort()\r\n","fwv_lst = np.zeros((train_user_number,len(order)))\r\n","\r\n","for person_idx, fwv in tqdm(id_error):\r\n","    fwv_lst[person_idx - train_user_id_min, np.where(order == fwv)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m4GaiuOhV2Se"},"source":["id_error = test_err_drop[['user_id','fwver']].values\r\n","order = test_err_drop['fwver'].unique()\r\n","order.sort()\r\n","fwv_test_lst = np.zeros((test_user_number,len(order)))\r\n","\r\n","for person_idx, fwv in tqdm(id_error):\r\n","    fwv_test_lst[person_idx - test_user_id_min, np.where(order == fwv)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AnKdbN6uYFDL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LbMJ01UVYFG-"},"source":["# quality data들의 fwver count\r\n","\r\n","train_quality['fwver'] = train_quality['fwver'].apply(string2num)\r\n","test_quality['fwver'] = test_quality['fwver'].apply(string2num)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7kiIjXTcYF40"},"source":["train_quality_fwv = train_quality['fwver'].unique()\r\n","test_quality_fwv = test_quality['fwver'].unique()\r\n","\r\n","# train_quality와 test_quality의 fwver 중 공통 부분만 추출\r\n","intersec_quality_fwv = np.array([x for x in test_quality_fwv if x in train_quality_fwv])\r\n","print(len(train_quality_fwv))\r\n","print(len(test_quality_fwv))\r\n","print(len(intersec_quality_fwv))\r\n","print(len([x for x in test_quality_fwv if x not in intersec_quality_fwv]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wPgO0qkO4pw7"},"source":["# 추출한 공통 부분에 해당하는 행들을 따로 추출\r\n","# test_quality에는 train_quality와 안 겹치는 fwver이 없으므로 따로 행 추출 필요 x\r\n","\r\n","train_quality_drop = train_quality[train_quality['fwver'].isin(intersec_quality_fwv)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WRqJHCO_Y0oz"},"source":["# train_quality_fwv 교집합을 제외한 부분\r\n","id_error = train_quality_drop[['user_id','fwver']].values\r\n","order = train_quality_drop['fwver'].unique()\r\n","order.sort()\r\n","fwv_quality_lst = np.zeros((train_user_number,len(order)))\r\n","\r\n","for person_idx, fwv in tqdm(id_error):\r\n","    fwv_quality_lst[person_idx - train_user_id_min, np.where(order == fwv)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qbxUUTN0aEyP"},"source":["# test_quality에는 train_quality와 겹치는 fwver밖에 없음\r\n","\r\n","id_error = test_quality[['user_id','fwver']].values\r\n","order = test_quality['fwver'].unique()\r\n","order.sort()\r\n","fwv_quality_test_lst = np.zeros((test_user_number,len(order)))\r\n","\r\n","for person_idx, fwv in tqdm(id_error):\r\n","    fwv_quality_test_lst[person_idx - test_user_id_min, np.where(order == fwv)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VG87TVG9cw7E"},"source":["## Model_nm"]},{"cell_type":"code","metadata":{"id":"sYhSFlfYaCjs"},"source":["train_err['model_nm'] = train_err['model_nm'].apply(string2num)\r\n","test_err['model_nm'] = test_err['model_nm'].apply(string2num)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ht6OJiFydLbH"},"source":["# train_err, test_err에는 model_nm이 0~8까지로 9개 존재\r\n","# model_nm을 count\r\n","\r\n","id_error = train_err[['user_id','model_nm']].values\r\n","model_nm = np.zeros((train_user_number,9))\r\n","\r\n","for person_idx, name in tqdm(id_error):\r\n","    model_nm[person_idx - train_user_id_min, name] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ekwTJbUweVoH"},"source":["id_error = test_err[['user_id','model_nm']].values\r\n","model_nm_test = np.zeros((test_user_number,9))\r\n","\r\n","for person_idx, name in tqdm(id_error):\r\n","    model_nm_test[person_idx - test_user_id_min, name] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jU8b3mfKgTBV"},"source":["## Hour"]},{"cell_type":"code","metadata":{"id":"zWna7kEmgVoD"},"source":["def make_hour(x):\r\n","    # string 타입의 Time column에서 월일을 추출\r\n","    x     = str(x)\r\n","    hour = x[8:10]\r\n","    return int(hour)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fwmiA7_RggCj"},"source":["# hour라는 새로운 컬럼 생성\r\n","train_err['hour'] = train_err['time'].apply(make_hour)\r\n","test_err['hour'] = test_err['time'].apply(make_hour)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8YnMO2ICg0DV"},"source":["print(len(train_err['hour'].unique()))\r\n","print(len(test_err['hour'].unique()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ys3cTkkzhJFI"},"source":["# train_err의 hour count\r\n","id_error = train_err[['user_id','hour']].values\r\n","order = train_err['hour'].unique()\r\n","order.sort()\r\n","hour = np.zeros((train_user_number,len(order)))\r\n","\r\n","for person_idx, h in tqdm(id_error):\r\n","    hour[person_idx - train_user_id_min, np.where(order == h)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fF2vOYylhDbl"},"source":["# test_err의 hour count\r\n","id_error = test_err[['user_id','hour']].values\r\n","order = test_err['hour'].unique()\r\n","order.sort()\r\n","hour_test = np.zeros((test_user_number,len(order)))\r\n","\r\n","for person_idx, mon_day in tqdm(id_error):\r\n","    hour_test[person_idx - test_user_id_min, np.where(order == mon_day)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oBHMpziChImg"},"source":["hour_df = pd.DataFrame(hour)\r\n","# hour_df.head()\r\n","hour_df['0_1'] = hour_df[23] + hour_df[0]\r\n","hour_df['2_3'] = hour_df[1] + hour_df[2]\r\n","hour_df['4_5'] = hour_df[3] + hour_df[4]\r\n","hour_df['6_7'] = hour_df[5] + hour_df[6]\r\n","hour_df['8_9'] = hour_df[7] + hour_df[8]\r\n","hour_df['10_11'] = hour_df[9] + hour_df[10]\r\n","hour_df['12_13'] = hour_df[11] + hour_df[12]\r\n","hour_df['14_15'] = hour_df[13] + hour_df[14]\r\n","hour_df['16_17'] = hour_df[15] + hour_df[16]\r\n","hour_df['18_19'] = hour_df[17] + hour_df[18]\r\n","hour_df['20_21'] = hour_df[19] + hour_df[20]\r\n","hour_df['22_23'] = hour_df[21] + hour_df[22]\r\n","# # hour_df.head()\r\n","hour_12 = hour_df.iloc[:, 24:]\r\n","hour_12 = hour_12/2\r\n","hour_12.head()\r\n","\r\n","# hour_df['0_6'] = hour_df[0] + hour_df[1] + hour_df[2] + hour_df[3] + hour_df[4] + hour_df[5]\r\n","# hour_df['6_12'] = hour_df[6] + hour_df[7] + hour_df[8] + hour_df[9] + hour_df[10] + hour_df[11]\r\n","# hour_df['13_18'] = hour_df[12] + hour_df[13] + hour_df[14] + hour_df[15] + hour_df[16] + hour_df[17]\r\n","# hour_df['19_24'] = hour_df[18] + hour_df[19] + hour_df[20] + hour_df[21] + hour_df[22] + hour_df[23]\r\n","\r\n","# hour_4 = hour_df.iloc[:, 24:]\r\n","# hour_4 = hour_4/6\r\n","# hour_4.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z7rkkSJMGBza"},"source":["## Minute"]},{"cell_type":"code","metadata":{"id":"As85X4kEDIBZ"},"source":["def make_minute(x):\r\n","    # string 타입의 Time column에서 월일을 추출\r\n","    x     = str(x)\r\n","    minute = x[10:12]\r\n","    return int(minute)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TD9_ZDUjDIP7"},"source":["# hour라는 새로운 컬럼 생성\r\n","train_err['minute'] = train_err['time'].apply(make_minute)\r\n","test_err['minute'] = test_err['time'].apply(make_minute)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pSSkczWTDnsG"},"source":["print(len(train_err['minute'].unique()))\r\n","print(len(test_err['minute'].unique()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WfMb6P_DvpC"},"source":["# train_err의 minute count\r\n","id_error = train_err[['user_id','minute']].values\r\n","order = train_err['minute'].unique()\r\n","order.sort()\r\n","minute = np.zeros((train_user_number,len(order)))\r\n","\r\n","for person_idx, h in tqdm(id_error):\r\n","    minute[person_idx - train_user_id_min, np.where(order == h)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8eBPWqNKD14b"},"source":["# test_err의 minute count\r\n","id_error = test_err[['user_id','minute']].values\r\n","order = test_err['minute'].unique()\r\n","order.sort()\r\n","minute_test = np.zeros((test_user_number,len(order)))\r\n","\r\n","for person_idx, mon_day in tqdm(id_error):\r\n","    minute_test[person_idx - test_user_id_min, np.where(order == mon_day)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Gt8JObFjynG"},"source":["## Quality Date count"]},{"cell_type":"code","metadata":{"id":"AkxPILMvj82e"},"source":["# month_day라는 새로운 컬럼 생성\r\n","train_quality['month_day'] = train_quality['time'].apply(make_datetime)\r\n","test_quality['month_day'] = test_quality['time'].apply(make_datetime)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o_6NVKz5j18t"},"source":["# train_quality의 Date count\r\n","# 1031 ~ 1130 31개\r\n","id_error = train_quality[['user_id','month_day']].values\r\n","order = train_quality['month_day'].unique()\r\n","order.sort()\r\n","quality_month_day = np.zeros((train_user_number,len(order)))\r\n","\r\n","for person_idx, mon_day in tqdm(id_error):\r\n","    quality_month_day[person_idx - train_user_id_min, np.where(order == mon_day)[0][0]] += 1\r\n","\r\n","# for person_idx, mon_day in tqdm(id_error):\r\n","#     month_day[person_idx - train_user_id_min, np.where(order == mon_day)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qKi6U8olkG0h"},"source":["# test_quality의 Date count\r\n","# 1031 ~ 1130 31개\r\n","id_error = test_quality[['user_id','month_day']].values\r\n","order = test_quality['month_day'].unique()\r\n","order.sort()\r\n","quality_month_day_test = np.zeros((test_user_number,len(order)))\r\n","\r\n","for person_idx, mon_day in tqdm(id_error):\r\n","    quality_month_day_test[person_idx - test_user_id_min, np.where(order == mon_day)[0][0]] += 1\r\n","\r\n","# for person_idx, mon_day in tqdm(id_error):\r\n","#     month_day_test[person_idx - test_user_id_min, np.where(order == mon_day)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Ymx57IEt2-2"},"source":["## Quality Hour count"]},{"cell_type":"code","metadata":{"id":"Xbiu_m1ftRxk"},"source":["# month_day라는 새로운 컬럼 생성\r\n","train_quality['hour'] = train_quality['time'].apply(make_hour)\r\n","test_quality['hour'] = test_quality['time'].apply(make_hour)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"91ElMXTwtnlw"},"source":["# train_quality의 hour count\r\n","\r\n","id_error = train_quality[['user_id','hour']].values\r\n","order = train_quality['hour'].unique()\r\n","order.sort()\r\n","quality_hour = np.zeros((train_user_number,len(order)))\r\n","\r\n","for person_idx, mon_day in tqdm(id_error):\r\n","    quality_hour[person_idx - train_user_id_min, np.where(order == mon_day)[0][0]] += 1\r\n","\r\n","# test_quality의 hour count\r\n","\r\n","id_error = test_quality[['user_id','hour']].values\r\n","order = test_quality['hour'].unique()\r\n","order.sort()\r\n","quality_hour_test = np.zeros((test_user_number,len(order)))\r\n","\r\n","for person_idx, mon_day in tqdm(id_error):\r\n","    quality_hour_test[person_idx - test_user_id_min, np.where(order == mon_day)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n-YYqRYx-6qG"},"source":["## Errcode count"]},{"cell_type":"code","metadata":{"id":"p69_zq_Fh7J1"},"source":["# str이 든 데이터를 임의로 9999로 매핑\r\n","\r\n","def string2num2(x):\r\n","    # (,)( )과 같은 불필요한 데이터 정제\r\n","    x = re.sub(r\"[^0-9]+\", '', str(x))\r\n","    if x =='':\r\n","        return 9999\r\n","    else:\r\n","        return int(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iiyxf23sjYIP"},"source":["train_err['code'] = train_err['errcode'].apply(string2num2)\r\n","test_err['code'] = test_err['errcode'].apply(string2num2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ShbEsy9j51A"},"source":["train_err_code = train_err.groupby(train_err['code'])['code'].count()\r\n","test_err_code = test_err.groupby(test_err['code'])['code'].count()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXrqLMDals2H"},"source":["# errcode count가 1000개 이상인 errcode들 추출\r\n","\r\n","train_err_code = train_err_code[train_err_code > 1000]\r\n","test_err_code = test_err_code[test_err_code > 1000]\r\n","\r\n","err_code_idx = train_err_code.index\r\n","err_code_test_idx = test_err_code.index\r\n","\r\n","err_code_idx = list(err_code_idx)\r\n","err_code_test_idx = list(err_code_test_idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NO-VLq2DoYx9"},"source":["intersec = [x for x in err_code_test_idx if x in err_code_idx]\r\n","print(len(err_code_idx))\r\n","print(len(err_code_test_idx))\r\n","print(len(intersec))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HWiK07fenGqW"},"source":["train_errcode = train_err[train_err['code'].isin(intersec)]\r\n","test_errcode = test_err[test_err['code'].isin(intersec)]\r\n","print(len(train_errcode))\r\n","print(len(test_errcode))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8OApqjeSWFYD"},"source":["# 공통 부분에 해당하지 않는 행들의 code은\r\n","# 기타로 취급하여 999999로 설정\r\n","train_errcode_etc = train_err[~train_err['code'].isin(intersec)]\r\n","test_errcode_etc = test_err[~test_err['code'].isin(intersec)]\r\n","\r\n","train_errcode_etc['code'] = 999999\r\n","test_errcode_etc['code'] = 999999\r\n","\r\n","id_error = train_errcode_etc[['user_id','code']].values\r\n","order = train_errcode_etc['code'].unique()\r\n","order.sort()\r\n","errcode_etc = np.zeros((train_user_number,len(order)))\r\n","\r\n","for person_idx, mon_day in tqdm(id_error):\r\n","    errcode_etc[person_idx - train_user_id_min, np.where(order == mon_day)[0][0]] += 1\r\n","\r\n","id_error = test_errcode_etc[['user_id','code']].values\r\n","order = test_errcode_etc['code'].unique()\r\n","order.sort()\r\n","errcode_etc_test = np.zeros((test_user_number,len(order)))\r\n","\r\n","for person_idx, mon_day in tqdm(id_error):\r\n","    errcode_etc_test[person_idx - test_user_id_min, np.where(order == mon_day)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MSbqjh0gltef"},"source":["id_error = train_errcode[['user_id','code']].values\r\n","order = intersec\r\n","order.sort()\r\n","errcode = np.zeros((train_user_number,len(order)))\r\n","\r\n","for person_idx, mon_day in tqdm(id_error):\r\n","    errcode[person_idx - train_user_id_min, np.where(order == mon_day)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LcaFm-AqvvbE"},"source":["id_error = test_errcode[['user_id','code']].values\r\n","order = intersec\r\n","order.sort()\r\n","errcode_test = np.zeros((test_user_number,len(order)))\r\n","\r\n","for person_idx, mon_day in tqdm(id_error):\r\n","    errcode_test[person_idx - test_user_id_min, np.where(order == mon_day)[0][0]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"77gUC9jRmXNC"},"source":["print(errcode.shape)\r\n","print(errcode_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z2A8IxdyYG2P"},"source":["## Concatenate"]},{"cell_type":"code","metadata":{"id":"cx2JwbEFLlre"},"source":["# 위에서 만든 변수들을 concatenate\r\n","X = np.concatenate((error, quality), axis = 1)\r\n","X = np.concatenate((X, month_day), axis = 1)\r\n","X = np.concatenate((X, fwv_lst), axis = 1)\r\n","# X = np.concatenate((X, fwv_etc_lst), axis = 1)\r\n","# X = np.concatenate((X, fwv_quality_lst), axis = 1)\r\n","X = np.concatenate((X, model_nm), axis = 1)\r\n","X = np.concatenate((X, hour), axis = 1)\r\n","# X = np.concatenate((X, minute), axis = 1)\r\n","# X = np.concatenate((X, quality_month_day), axis = 1)\r\n","# X = np.concatenate((X, quality_hour), axis = 1)\r\n","X = np.concatenate((X, errcode), axis = 1)\r\n","# X = np.concatenate((X, errcode_etc), axis = 1)\r\n","Y = problem\r\n","print(X.shape)\r\n","print(Y.shape)\r\n","\r\n","X_test = np.concatenate((test_x, quality_test), axis = 1)\r\n","X_test = np.concatenate((X_test, test_date.values), axis = 1)\r\n","X_test = np.concatenate((X_test, fwv_test_lst), axis = 1)\r\n","# X_test = np.concatenate((X_test, fwv_etc_test_lst), axis = 1)\r\n","# X_test = np.concatenate((X_test, fwv_quality_test_lst), axis = 1)\r\n","X_test = np.concatenate((X_test, model_nm_test), axis = 1)\r\n","X_test = np.concatenate((X_test, hour_test), axis = 1)\r\n","# X_test = np.concatenate((X_test, minute_test), axis = 1)\r\n","# X_test = np.concatenate((X_test, quality_month_day_test), axis = 1)\r\n","# X_test = np.concatenate((X_test, quality_hour_test), axis = 1)\r\n","X_test = np.concatenate((X_test, errcode_test), axis = 1)\r\n","# X_test = np.concatenate((X_test, errcode_etc_test), axis = 1)\r\n","print(X_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0_p9jkXtXF_r"},"source":["# error, quality, month_day, fwv_lst, fwv_quality_lst, model_nm, hour -> 0.81873\r\n","# error, quality, month_day, fwv_lst, fwv_quality_lst, model_nm, hour, errcode -> 0.82052\r\n","# error, quality, month_day, fwv_lst, fwv_quality_lst, model_nm, hour, minute, errcode -> 0.81811\r\n","# error, quality, month_day, fwv_lst, model_nm, hour, errcode -> 0.82091\r\n","\r\n","train_x = X\r\n","train_y = problem\r\n","\r\n","print(train_x.shape)\r\n","print(train_y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9XyG5jxB--hG"},"source":["## NN"]},{"cell_type":"code","metadata":{"id":"9ff_Jq8M3cpx"},"source":["# Normalization\r\n","from sklearn.preprocessing import MinMaxScaler\r\n","scaler = MinMaxScaler()\r\n","scaler.fit(X)\r\n","X = scaler.transform(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HgebIJdV2QXX"},"source":["# def build_nn():\r\n","models     = []\r\n","auc_scores   = []\r\n","\r\n","k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\r\n","for train_idx, val_idx in k_fold.split(train_x):\r\n","\r\n","    # split train, validation set\r\n","    X = train_x[train_idx]\r\n","    y = train_y[train_idx]\r\n","    valid_x = train_x[val_idx]\r\n","    valid_y = train_y[val_idx]\r\n","\r\n","    # d_train= lgbm.Dataset(X, y)\r\n","    # d_val  = lgbm.Dataset(valid_x, valid_y)\r\n","\r\n","    earlystop = EarlyStopping(patience=30)\r\n","    learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\r\n","                                            patience=2,\r\n","                                            factor=0.8,\r\n","                                            min_lr=1e-7,\r\n","                                            verbose=1)\r\n","    model_check = ModelCheckpoint( #에포크마다 현재 가중치를 저장    \r\n","            filepath=\"./lg_nn.h5\", #모델 파일 경로\r\n","            monitor='val_loss',  # val_loss 가 좋아지지 않으면 모델 파일을 덮어쓰지 않음.\r\n","            save_best_only=True)\r\n","\r\n","    callbacks = [earlystop, learning_rate_reduction, model_check]\r\n","\r\n","    model = Sequential()\r\n","    model.add(Dense(1024, kernel_initializer='he_normal',\r\n","                    input_shape=(X.shape[1],)))  # input_shape로 input layer의 역할까지도 처리\r\n","    model.add(PReLU())\r\n","    model.add(BatchNormalization())\r\n","    model.add(Dropout(0.5))\r\n","\r\n","    model.add(Dense(512, kernel_initializer='he_normal'))\r\n","    model.add(PReLU())\r\n","    model.add(BatchNormalization())\r\n","    model.add(Dropout(0.5))\r\n","\r\n","    model.add(Dense(256, kernel_initializer='he_normal'))\r\n","    model.add(PReLU())\r\n","    model.add(BatchNormalization())\r\n","    model.add(Dropout(0.5))\r\n","\r\n","    model.add(Dense(1, activation='sigmoid', kernel_initializer='he_normal'))\r\n","\r\n","    model.compile(optimizer=Adam(learning_rate=0.005),\r\n","                loss='binary_crossentropy',\r\n","                metrics=[AUC()])\r\n","\r\n","    history = model.fit(X,\r\n","                        y,\r\n","                        epochs=1000,\r\n","                        verbose=1,\r\n","                        validation_data=(valid_x,valid_y),\r\n","                        callbacks=callbacks)\r\n","    \r\n","    # cal valid prediction\r\n","    valid_prob = model.predict_proba(valid_x)\r\n","    valid_prob = valid_prob.reshape(-1)\r\n","    valid_pred = np.where(valid_prob > threshold, 1, 0)\r\n","    valid_pred = valid_pred.reshape(-1)\r\n","    print(valid_prob)\r\n","    print(valid_y)\r\n","    print(valid_pred)\r\n","    # cal scores\r\n","    auc_score = roc_auc_score(   valid_y, valid_prob)\r\n","\r\n","    # append scores\r\n","    models.append(model)\r\n","    auc_scores.append(auc_score)\r\n","    \r\n","    # return history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fX5yU4cC548u"},"source":["print(np.mean(auc_scores))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6TW82w-oWa8C"},"source":["## LGBM"]},{"cell_type":"code","metadata":{"id":"4CERxOtWWZvy"},"source":["from sklearn.model_selection import KFold\r\n","from sklearn.metrics import precision_recall_curve, auc, recall_score, precision_score\r\n","\r\n","def f_pr_auc(probas_pred, y_true):\r\n","    labels=y_true.get_label()\r\n","    p, r, _ = precision_recall_curve(labels, probas_pred)\r\n","    score=auc(r,p)\r\n","    return \"pr_auc\", score, True\r\n","\r\n","#-------------------------------------------------------------------------------------\r\n","models     = []\r\n","recalls    = []\r\n","precisions = []\r\n","auc_scores   = []\r\n","threshold = 0.5\r\n","# 파라미터 설정\r\n","params =      {\r\n","                'boosting_type' : 'gbdt',\r\n","                'objective'     : 'binary',\r\n","                'metric'        : 'auc',\r\n","                'seed': 1015,\r\n","               \r\n","                'application': 'binary',\r\n","                'max_depth ': 20,\r\n","                'is_unbalance': 'true',\r\n","                # 'num_leaves': 1000,\r\n","                'feature_fraction': 0.75,\r\n","                'bagging_fraction': 0.75,\r\n","                # 'subsample ': 0.9,\r\n","                'bagging_freq': 20,\r\n","                'learning_rate': 0.008,\r\n","                'verbose': 0\r\n","                }\r\n","#-------------------------------------------------------------------------------------\r\n","# 5 Kfold cross validation\r\n","k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\r\n","for train_idx, val_idx in k_fold.split(train_x):\r\n","\r\n","    # split train, validation set\r\n","    X = train_x[train_idx]\r\n","    y = train_y[train_idx]\r\n","    valid_x = train_x[val_idx]\r\n","    valid_y = train_y[val_idx]\r\n","\r\n","    d_train= lgbm.Dataset(X, y)\r\n","    d_val  = lgbm.Dataset(valid_x, valid_y)\r\n","    \r\n","    #run traning\r\n","    model = lgbm.train(\r\n","                        params,\r\n","                        train_set       = d_train,\r\n","                        num_boost_round = 10000,\r\n","                        valid_sets      = d_val,\r\n","                        feval           = f_pr_auc,\r\n","                        verbose_eval    = 20, \r\n","                        early_stopping_rounds = 1000\r\n","                       )\r\n","    \r\n","    # cal valid prediction\r\n","    valid_prob = model.predict(valid_x)\r\n","    # print(valid_prob)\r\n","    valid_pred = np.where(valid_prob > threshold, 1, 0)\r\n","    # print(valid_pred)\r\n","    \r\n","    # cal scores\r\n","    recall    = recall_score(    valid_y, valid_pred)\r\n","    precision = precision_score( valid_y, valid_pred)\r\n","    auc_score = roc_auc_score(   valid_y, valid_prob)\r\n","\r\n","    # append scores\r\n","    models.append(model)\r\n","    recalls.append(recall)\r\n","    precisions.append(precision)\r\n","    auc_scores.append(auc_score)\r\n","\r\n","    print('==========================================================')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oasozf3wXKdA"},"source":["print(np.mean(auc_scores))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6x7yWOyZXOXK"},"source":["pred_y_list = []\r\n","for model in models:\r\n","    pred_y = model.predict(X_test)\r\n","    pred_y_list.append(pred_y.reshape(-1,1))\r\n","    \r\n","lgbm_pred_ensemble = np.mean(pred_y_list, axis = 0)\r\n","lgbm_pred_ensemble"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ls2jZ6g3i5ra"},"source":["sample_submssion = pd.read_csv('/content/drive/MyDrive/Colab/data/LG/sample_submission.csv')\r\n","sample_submssion['problem'] = lgbm_pred_ensemble.reshape(-1)\r\n","sample_submssion.to_csv(\"/content/drive/MyDrive/Colab/data/LG/lgbm_0.82163.csv\", index = False)\r\n","sample_submssion"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VVilyvhFwCg9"},"source":["## Xgboost"]},{"cell_type":"code","metadata":{"id":"AYaoAhsmwEdD"},"source":["import xgboost as xgb\r\n","\r\n","def f_pr_auc(probas_pred, y_true):\r\n","    labels=y_true.get_label()\r\n","    p, r, _ = precision_recall_curve(labels, probas_pred)\r\n","    score=auc(r,p) \r\n","    return \"pr_auc\", score\r\n","#-------------------------------------------------------------------------------------\r\n","models     = []\r\n","recalls    = []\r\n","precisions = []\r\n","auc_scores   = []\r\n","threshold = 0.5\r\n","# 파라미터 설정\r\n","params =      {\r\n","                # 'boosting_type' : 'gbdt',\r\n","                'objective'     : 'binary:logistic',\r\n","                'eval_metric'   : 'auc',\r\n","                'seed': 1015,\r\n","            \r\n","                # 'application': 'binary',\r\n","                'max_depth ': 4,\r\n","                'is_unbalance': 'true',\r\n","                # 'num_leaves': 55,\r\n","                # 'feature_fraction': 0.75,\r\n","                # 'bagging_fraction': 0.75,\r\n","                # 'bagging_freq': 20,\r\n","                'eta': 0.028,\r\n","                # 'reg_lambda': 1,\r\n","                'subsample' : 0.7, \r\n","                'verbose': 0\r\n","                }\r\n","#-------------------------------------------------------------------------------------\r\n","# 5 Kfold cross validation\r\n","k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\r\n","for train_idx, val_idx in k_fold.split(train_x):\r\n","\r\n","    # split train, validation set\r\n","    X = train_x[train_idx]\r\n","    y = train_y[train_idx]\r\n","    valid_x = train_x[val_idx]\r\n","    valid_y = train_y[val_idx]\r\n","\r\n","    d_train= xgb.DMatrix(X, y)\r\n","    d_val  = xgb.DMatrix(valid_x, valid_y)\r\n","    \r\n","    d_valid_x = xgb.DMatrix(valid_x)\r\n","\r\n","    #run traning\r\n","    model = xgb.train(\r\n","                        params,\r\n","                        dtrain       = d_train,\r\n","                        num_boost_round = 10000,\r\n","                        evals      = [(d_train, 'train'), (d_val, 'eval')],\r\n","                        feval           = f_pr_auc,\r\n","                        verbose_eval    = 20, \r\n","                        early_stopping_rounds = 500\r\n","                       )\r\n","    \r\n","    # # cal valid prediction\r\n","    valid_prob = model.predict(d_valid_x)\r\n","    # print(valid_prob)\r\n","    valid_pred = np.where(valid_prob > threshold, 1, 0)\r\n","    \r\n","    # # cal scores\r\n","    recall    = recall_score(    valid_y, valid_pred)\r\n","    precision = precision_score( valid_y, valid_pred)\r\n","    auc_score = roc_auc_score(   valid_y, valid_prob)\r\n","\r\n","    # # append scores\r\n","    models.append(model)\r\n","    recalls.append(recall)\r\n","    precisions.append(precision)\r\n","    auc_scores.append(auc_score)\r\n","\r\n","    print('==========================================================')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"brnWfZPrwGP9"},"source":["print(np.mean(auc_scores))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NDA9C_lwwJmN"},"source":["d_test_x = xgb.DMatrix(X_test)\r\n","\r\n","pred_y_list = []\r\n","for model in models:\r\n","    pred_y = model.predict(d_test_x)\r\n","    pred_y_list.append(pred_y.reshape(-1,1))\r\n","    \r\n","xgb_pred_ensemble = np.mean(pred_y_list, axis = 0)\r\n","print(xgb_pred_ensemble)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G3-XZWDAd52v"},"source":["## Catboost"]},{"cell_type":"code","metadata":{"id":"-CTXln54YwUr"},"source":["!pip install catboost"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EixRra9nax-Q"},"source":["# l2-2, depth:6 -> 82066\r\n","# l2-2, depth:8, subsample:0.9, Bernoulli -> 82163\r\n","# l2-2, depth:9, subsample:0.9, Bernoulli -> 82172\r\n","from catboost import CatBoostClassifier\r\n","\r\n","cat_params = {\r\n","        'n_estimators': 100000,\r\n","        'learning_rate': 0.012,\r\n","        'eval_metric': 'AUC',\r\n","        # 'loss_function': 'Logloss',\r\n","        'bootstrap_type': 'Bernoulli',\r\n","        'loss_function': 'MultiClass',\r\n","        'random_seed': 42,\r\n","        'metric_period': 500,\r\n","        'od_wait': 500,\r\n","        'task_type': 'GPU',\r\n","        'l2_leaf_reg' : 2,\r\n","        'depth': 9,\r\n","        'subsample' : 0.9,\r\n","        'use_best_model': True\r\n","    }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1kYqEh_zbG9k"},"source":["models     = []\r\n","auc_scores   = []\r\n","threshold = 0.5\r\n","\r\n","k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\r\n","for train_idx, val_idx in k_fold.split(train_x):\r\n","\r\n","    # split train, validation set\r\n","    X = train_x[train_idx]\r\n","    y = train_y[train_idx]\r\n","    valid_x = train_x[val_idx]\r\n","    valid_y = train_y[val_idx]\r\n","\r\n","    #run traning\r\n","    model = CatBoostClassifier(**cat_params)\r\n","    model.fit(X, y, eval_set = (valid_x, valid_y), verbose=True)\r\n","    # print(model.get_best_score())\r\n","\r\n","    # cal valid prediction\r\n","    valid_prob = model.predict_proba(valid_x)\r\n","    valid_prob = valid_prob[:, 1]\r\n","    valid_pred = np.where(valid_prob > threshold, 1, 0)\r\n","    valid_pred = valid_pred.reshape(-1)\r\n","\r\n","    # cal scores\r\n","    auc_score = roc_auc_score(valid_y, valid_prob)\r\n","\r\n","    # append scores\r\n","    models.append(model)\r\n","    auc_scores.append(auc_score)\r\n","\r\n","    print('==========================================================')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKRKGAbybHB2"},"source":["print(np.mean(auc_scores))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oIRhVSRobHEb"},"source":["pred_y_list = []\r\n","for model in models:\r\n","    pred_y = model.predict_proba(X_test)\r\n","    pred_y = pred_y[:, 1]\r\n","    pred_y_list.append(pred_y.reshape(-1,1))\r\n","    \r\n","catboost_pred_ensemble = np.mean(pred_y_list, axis = 0)\r\n","catboost_pred_ensemble"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xgnyc9uf1LyS"},"source":["cat_lgbm_ensemble = (catboost_pred_ensemble.ravel() + lgbm_pred_ensemble.ravel() + xgb_pred_ensemble.ravel()) / 3\r\n","cat_lgbm_ensemble"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K-3WES-5vsmN"},"source":["sample_submssion = pd.read_csv('/content/drive/MyDrive/Colab/data/LG/sample_submission.csv')\r\n","sample_submssion['problem'] = cat_lgbm_ensemble\r\n","sample_submssion.to_csv(\"/content/drive/MyDrive/Colab/data/LG/cat82197_lgbm82163_xgb81988_ensemble.csv\", index = False)\r\n","sample_submssion"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFDU22Vm4WXH"},"source":["## 더미\r\n","\r\n","# # train_err_fwv 교집합을 제외한 부분\r\n","# remove_fwv = [x for x in train_err_fwv if x not in intersec_err_fwv]\r\n","\r\n","# first_remove_fwv = train_err[train_err['fwver'] == remove_fwv[0]].index\r\n","# train_err_drop = train_err.drop(first_remove_fwv)\r\n","\r\n","# for drop_fwv in remove_fwv[1:]:\r\n","#     rmv_fwv = train_err[train_err['fwver'] == drop_fwv].index\r\n","#     train_err_drop = train_err_drop.drop(rmv_fwv)\r\n","\r\n","# # test_err_fwv 교집합을 제외한 부분\r\n","# remove_fwv_test = [x for x in test_err_fwv if x not in intersec_err_fwv]\r\n","\r\n","# first_remove_fwv = test_err[test_err['fwver'] == remove_fwv_test[0]].index\r\n","# test_err_drop = test_err.drop(first_remove_fwv)\r\n","\r\n","# for drop_fwv in remove_fwv_test[1:]:\r\n","#     rmv_fwv = test_err[test_err['fwver'] == drop_fwv].index\r\n","#     test_err_drop = test_err_drop.drop(rmv_fwv)\r\n","\r\n","\r\n","# # train_quality_fwv 교집합을 제외한 부분\r\n","# remove_quality_fwv = [x for x in train_quality_fwv if x not in intersec_quality_fwv]\r\n","\r\n","# first_remove_fwv = train_quality[train_quality['fwver'] == remove_quality_fwv[0]].index\r\n","# train_quality_drop = train_quality.drop(first_remove_fwv)\r\n","\r\n","# for drop_fwv in remove_quality_fwv[1:]:\r\n","#     rmv_fwv = train_quality[train_quality['fwver'] == drop_fwv].index\r\n","#     train_quality_drop = train_quality_drop.drop(rmv_fwv)"],"execution_count":null,"outputs":[]}]}