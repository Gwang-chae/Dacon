{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Motion_Keypoint.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["XNMLhaU0aGgv"],"machine_shape":"hm","mount_file_id":"1nEZ5nRNMVFJU4LdOM-QgTuSkY7j0s2_h","authorship_tag":"ABX9TyPi3g5bZ31ComXqfIxXPVAK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xiVChnFFaw-W"},"source":["import cv2\r\n","import glob\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","import os\r\n","import pandas as pd\r\n","import random\r\n","import shutil\r\n","import tensorflow as tf\r\n","\r\n","from PIL import Image\r\n","from tqdm import tqdm\r\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, concatenate, Input, Flatten, Dense\r\n","from tensorflow.keras import Model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN5cNKPBbILg"},"source":["os.chdir('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/data') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0FdpC4sccl2"},"source":["train = pd.read_csv('./train.csv')\r\n","valid = pd.read_csv('./valid.csv')\r\n","display(train.head(2))\r\n","print()\r\n","display(valid.head(2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PFtkUP1wckBD"},"source":["# train.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pp7WxRtIcqPf"},"source":["train_paths = glob.glob('./train/*.jpg')\r\n","valid_paths = glob.glob('./valid/*.jpg')\r\n","test_paths = glob.glob('./test_imgs/*.jpg')\r\n","print(len(train_paths), len(valid_paths), len(test_paths))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"puxbBBA_gzwe"},"source":["train_paths.sort()\r\n","valid_paths.sort()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XNMLhaU0aGgv"},"source":["### Train, Valid Split"]},{"cell_type":"code","metadata":{"id":"ZQ4y1N-QW15L"},"source":["# root_dir = '/content/drive/My Drive/Colab/Dacon/Motion_Keypoint/data'\r\n","\r\n","# os.makedirs(root_dir +'/train')\r\n","# os.makedirs(root_dir +'/val')\r\n","\r\n","src = \"train_imgs\"\r\n","all_filename = os.listdir(src)\r\n","valid_filename = random.sample(all_filename, int(len(train_all) * 0.1))\r\n","train_filename = [x for x in all_filename if x not in valid_filename]\r\n","\r\n","print(len(train_filename), len(valid_filename))\r\n","\r\n","train_filename = [src+'/'+ name for name in train_filename]\r\n","valid_filename = [src+'/' + name for name in valid_filename]\r\n","\r\n","print('Total images: ', len(all_filename))\r\n","print('Training: ', len(train_filename))\r\n","print('Validation: ', len(valid_filename))\r\n","\r\n","# Copy-pasting images\r\n","for name in tqdm(train_filename):\r\n","    shutil.copy(name, 'train')\r\n","\r\n","for name in tqdm(valid_filename):\r\n","    shutil.copy(name, 'val')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0NjamAo6VnfC"},"source":["train_filename = []\r\n","valid_filename = []\r\n","\r\n","for t_paths in tqdm(train_paths):\r\n","    filename = t_paths.split('/')[-1]\r\n","    train_filename.append(filename)\r\n","\r\n","for v_paths in tqdm(valid_paths):\r\n","    filename = v_paths.split('/')[-1]\r\n","    valid_filename.append(filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjHZ4r8RWGgm"},"source":["train_df = train[train['image'].isin(train_filename)]\r\n","train_df.reset_index(inplace=True, drop=True)\r\n","\r\n","valid_df = train[train['image'].isin(valid_filename)]\r\n","valid_df.reset_index(inplace=True, drop=True)\r\n","\r\n","train_df.to_csv('train.csv', index=False)\r\n","valid_df.to_csv('valid.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6N5SgmWaaNbI"},"source":["### 시각화"]},{"cell_type":"code","metadata":{"id":"_MWkTSqMdA9J"},"source":["plt.figure(figsize=(40,20))\r\n","count=1\r\n","\r\n","for i in np.random.randint(0,len(train_paths),5):\r\n","    \r\n","    plt.subplot(5,1, count)\r\n","    \r\n","    img_sample_path = train_paths[i]\r\n","    img = Image.open(img_sample_path)\r\n","    img_np = np.array(img)\r\n","\r\n","    keypoint = train.iloc[:,1:49] #위치 키포인트 하나씩 확인\r\n","    keypoint_sample = keypoint.iloc[i, :]\r\n","    \r\n","    for j in range(0,len(keypoint.columns),2):\r\n","        plt.plot(keypoint_sample[j], keypoint_sample[j+1],'rx')\r\n","        plt.imshow(img_np)\r\n","    \r\n","    count += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qTsdSCJEI-1l"},"source":["train['path'] = train_paths\r\n","# train\r\n","valid['path'] = valid_paths\r\n","print(len(train['path']))\r\n","print(len(valid['path']))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W01kd-M9Uazm"},"source":["### Augmentation"]},{"cell_type":"code","metadata":{"id":"hbPNQUydN_cd"},"source":["def left_right_flip(images, keypoints):\r\n","    flipped_keypoints = []\r\n","    flipped_images = np.flip(images, axis=1)\r\n","    for idx, sample_keypoints in enumerate(keypoints):\r\n","        if idx%2 == 0:\r\n","            flipped_keypoints.append(480.-sample_keypoints)\r\n","        else:\r\n","            flipped_keypoints.append(sample_keypoints)\r\n","    return flipped_images, flipped_keypoints"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvLxZDpzIeuK"},"source":["def trainGenerator():\r\n","    # 원본 이미지 resize\r\n","    for i in range(len(train)):\r\n","        img = tf.io.read_file(train['path'][i]) # path(경로)를 통해 이미지 읽기\r\n","        img = tf.image.decode_jpeg(img, channels=3) # 경로를 통해 불러온 이미지를 tensor로 변환\r\n","        img = tf.image.resize(img, [270,480]) # 이미지 resize \r\n","        img = img/255\r\n","        target = train.iloc[:,1:49].iloc[i,:] # keypoint 뽑아주기\r\n","        target = target/4\r\n","\r\n","        yield (img, target)\r\n","    \r\n","    # horizontal flip\r\n","    for i in range(len(train)):\r\n","        img = tf.io.read_file(train['path'][i]) # path(경로)를 통해 이미지 읽기\r\n","        img = tf.image.decode_jpeg(img, channels=3) # 경로를 통해 불러온 이미지를 tensor로 변환\r\n","        img = tf.image.resize(img, [270,480]) # 이미지 resize \r\n","        img = img/255\r\n","        target = train.iloc[:,1:49].iloc[i,:] # keypoint 뽑아주기\r\n","        target = target/4\r\n","        img, target = left_right_flip(img, target)\r\n","        \r\n","        yield (img, target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ocMXeBkxWPjE"},"source":["def validGenerator():\r\n","    # 원본 이미지 resize\r\n","    for i in range(len(valid)):\r\n","        img = tf.io.read_file(valid['path'][i]) # path(경로)를 통해 이미지 읽기\r\n","        img = tf.image.decode_jpeg(img, channels=3) # 경로를 통해 불러온 이미지를 tensor로 변환\r\n","        img = tf.image.resize(img, [270,480]) # 이미지 resize \r\n","        img = img/255\r\n","        target = valid.iloc[:,1:49].iloc[i,:] # keypoint 뽑아주기\r\n","        target = target/4\r\n","\r\n","        yield (img, target)\r\n","    \r\n","    # horizontal flip\r\n","    for i in range(len(valid)):\r\n","        img = tf.io.read_file(valid['path'][i]) # path(경로)를 통해 이미지 읽기\r\n","        img = tf.image.decode_jpeg(img, channels=3) # 경로를 통해 불러온 이미지를 tensor로 변환\r\n","        img = tf.image.resize(img, [270,480]) # 이미지 resize \r\n","        img = img/255\r\n","        target = valid.iloc[:,1:49].iloc[i,:] # keypoint 뽑아주기\r\n","        target = target/4\r\n","        img, target = left_right_flip(img, target)\r\n","        \r\n","        yield (img, target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eYUf2ulVJGE0"},"source":["train_dataset = tf.data.Dataset.from_generator(trainGenerator, (tf.float32, tf.float32), (tf.TensorShape([270,480,3]),tf.TensorShape([48])))\r\n","train_dataset = train_dataset.batch(32).prefetch(1)\r\n","valid_dataset = tf.data.Dataset.from_generator(validGenerator, (tf.float32, tf.float32), (tf.TensorShape([270,480,3]),tf.TensorShape([48])))\r\n","valid_dataset = valid_dataset.batch(32).prefetch(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p6qLRNnXM85L"},"source":["a = list(train_dataset)[0][0]\r\n","t = list(train_dataset)[0][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ef5_6Pd_NBPy"},"source":["plt.imshow(a)\r\n","plt.scatter(t[0::2], t[1::2], marker='x')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wovM-Ltkda9y"},"source":["horizontal_flip = True\r\n","rotation_augmentation = True\r\n","brightness_augmentation = True\r\n","shift_augmentation = True\r\n","random_noise_augmentation = True\r\n","\r\n","sample_image_index = 20    # Index of sample train image used for visualizing various augmentations\r\n","\r\n","rotation_angles = [12]    # Rotation angle in degrees (includes both clockwise & anti-clockwise rotations)\r\n","pixel_shifts = [12]    # Horizontal & vertical shift amount in pixels (includes shift from all 4 corners)\r\n","\r\n","NUM_EPOCHS = 80\r\n","BATCH_SIZE = 64"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sv2kOvrKuHG1"},"source":["from keras.layers.advanced_activations import LeakyReLU\r\n","from keras.models import Sequential, Model\r\n","from keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UWt17FcZVW1x"},"source":["model = Sequential()\r\n","\r\n","# Input dimensions: (None, 96, 96, 1)\r\n","model.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape=(270,480,3)))\r\n","model.add(LeakyReLU(alpha = 0.1))\r\n","model.add(BatchNormalization())\r\n","# Input dimensions: (None, 96, 96, 32)\r\n","model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\r\n","model.add(LeakyReLU(alpha = 0.1))\r\n","model.add(BatchNormalization())\r\n","model.add(MaxPool2D(pool_size=(2, 2)))\r\n","\r\n","# Input dimensions: (None, 48, 48, 32)\r\n","model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\r\n","model.add(LeakyReLU(alpha = 0.1))\r\n","model.add(BatchNormalization())\r\n","# Input dimensions: (None, 48, 48, 64)\r\n","model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\r\n","model.add(LeakyReLU(alpha = 0.1))\r\n","model.add(BatchNormalization())\r\n","model.add(MaxPool2D(pool_size=(2, 2)))\r\n","\r\n","# Input dimensions: (None, 24, 24, 64)\r\n","model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\r\n","model.add(LeakyReLU(alpha = 0.1))\r\n","model.add(BatchNormalization())\r\n","# Input dimensions: (None, 24, 24, 96)\r\n","model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\r\n","model.add(LeakyReLU(alpha = 0.1))\r\n","model.add(BatchNormalization())\r\n","model.add(MaxPool2D(pool_size=(2, 2)))\r\n","\r\n","# Input dimensions: (None, 12, 12, 96)\r\n","model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\r\n","model.add(LeakyReLU(alpha = 0.1))\r\n","model.add(BatchNormalization())\r\n","# Input dimensions: (None, 12, 12, 128)\r\n","model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\r\n","model.add(LeakyReLU(alpha = 0.1))\r\n","model.add(BatchNormalization())\r\n","model.add(MaxPool2D(pool_size=(2, 2)))\r\n","\r\n","# Input dimensions: (None, 6, 6, 128)\r\n","model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\r\n","model.add(LeakyReLU(alpha = 0.1))\r\n","model.add(BatchNormalization())\r\n","# Input dimensions: (None, 6, 6, 256)\r\n","model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\r\n","model.add(LeakyReLU(alpha = 0.1))\r\n","model.add(BatchNormalization())\r\n","model.add(MaxPool2D(pool_size=(2, 2)))\r\n","\r\n","# Input dimensions: (None, 3, 3, 256)\r\n","model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\r\n","model.add(LeakyReLU(alpha = 0.1))\r\n","model.add(BatchNormalization())\r\n","# Input dimensions: (None, 3, 3, 512)\r\n","model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\r\n","model.add(LeakyReLU(alpha = 0.1))\r\n","model.add(BatchNormalization())\r\n","\r\n","# Input dimensions: (None, 3, 3, 512)\r\n","model.add(Flatten())\r\n","model.add(Dense(512,activation='relu'))\r\n","model.add(Dropout(0.1))\r\n","model.add(Dense(48))\r\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NU2LA5pzVgxT"},"source":["from tensorflow.keras.optimizers import Adam\r\n","\r\n","model.compile(optimizer=Adam(learning_rate=0.001), \r\n","              loss='mean_squared_error',\r\n","              metrics=['mae'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fWXednbuVlxl"},"source":["history = model.fit(train_dataset,\r\n","                    epochs=5,\r\n","                    validation_data=valid_dataset,\r\n","                    verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aE4fg_dBaNAR"},"source":["test_paths.sort()\r\n","X_test=[]\r\n","\r\n","for test_path in tqdm(test_paths):\r\n","    img=tf.io.read_file(test_path)\r\n","    img=tf.image.decode_jpeg(img, channels=3)\r\n","    img=tf.image.resize(img, [270,480])\r\n","    img=img/255\r\n","    X_test.append(img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Djg3Ija9aOWc"},"source":["X_test=tf.stack(X_test, axis=0)\r\n","X_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6GVLAqQaR1V"},"source":["pred=model.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Isxqz6XcaTRd"},"source":["submission = pd.read_csv('./sample_submission.csv')\r\n","submission.iloc[:,1:]=pred * 4\r\n","submission"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L5If665wq32N"},"source":["test_paths[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H48nCNeap3w6"},"source":["bb = submission.iloc[1000,1:49]\r\n","bb = np.array(bb)\r\n","aa = Image.open(test_paths[1000])\r\n","plt.imshow(aa)\r\n","plt.scatter(bb[0::2], bb[1::2], marker='x')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XnqDaAKrabS8"},"source":["submission.to_csv('baseline_submission.csv', index=False)"],"execution_count":null,"outputs":[]}]}