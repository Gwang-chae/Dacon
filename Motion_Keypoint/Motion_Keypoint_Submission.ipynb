{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Motion_Keypoint_Submission.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzBxDxB5l0xR"
      },
      "source": [
        "# IDEA\n",
        "1. Object Detection -> test_imgs의 bbox 파일 생성\n",
        "    * 1-1) train / valid set split\n",
        "        * train set으로 외부데이터 추가\n",
        "    * 1-2) train / valid / test set을 COCO format으로 변경\n",
        "    * 1-3) DetectoRS 모델 학습\n",
        "\n",
        "2. Keypoint Detection\n",
        "    * 2-1) train / valid / test set을 Keypoint Detection을 위한 형태로 변경\n",
        "    * 2-2) DarkPose 모델 학습\n",
        "    * 2-3) Submission file 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgV13skFjSqY"
      },
      "source": [
        "## 1-1) Train / Valid set split\n",
        "* train 90% 3776장\n",
        "* valid 10% 419장으로 나눴습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLfBP6nxhf5r"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import json\n",
        "\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from collections import OrderedDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIlGjgTrjes2"
      },
      "source": [
        "# 경로 이동\n",
        "os.chdir('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/')\n",
        "\n",
        "# train, val folder 생성\n",
        "root_dir = '/content/drive/My Drive/Colab/Dacon/Motion_Keypoint/'\n",
        "\n",
        "os.makedirs(root_dir +'/train')\n",
        "os.makedirs(root_dir +'/val')\n",
        "\n",
        "# validation용 파일은 10% 비율로 random sampling\n",
        "random.seed(42)\n",
        "src = \"train_imgs\"\n",
        "all_filename = os.listdir(src)\n",
        "valid_filename = random.sample(all_filename, int(len(train_all) * 0.1))\n",
        "train_filename = [x for x in all_filename if x not in valid_filename]\n",
        "\n",
        "print(len(train_filename), len(valid_filename))\n",
        "\n",
        "train_filename = [src+'/'+ name for name in train_filename]\n",
        "valid_filename = [src+'/' + name for name in valid_filename]\n",
        "\n",
        "print('Total images: ', len(all_filename))\n",
        "print('Training: ', len(train_filename))\n",
        "print('Validation: ', len(valid_filename))\n",
        "\n",
        "# copy & paste images\n",
        "for name in tqdm(train_filename):\n",
        "    shutil.copy(name, 'train')\n",
        "\n",
        "for name in tqdm(valid_filename):\n",
        "    shutil.copy(name, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Tm0K33olN9Q"
      },
      "source": [
        "# DACON 제공 train_imgs.csv read\n",
        "train =pd.read_csv(root_dir + 'train_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEEDGWm6j4J7"
      },
      "source": [
        "# 각각의 train, valid 이미지들의 정보만을 담고 있는 DataFrame 생성\n",
        "train_df = train[train['image'].isin(train_filename)]\n",
        "train_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "valid_df = train[train['image'].isin(valid_filename)]\n",
        "valid_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "train_df.to_csv('train.csv', index=False)\n",
        "valid_df.to_csv('valid.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXlqeH9KlmK_"
      },
      "source": [
        "# Colab상 경로 재설정\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCBOk3sNn6z6"
      },
      "source": [
        "### Train set으로 외부데이터 추가\n",
        "(AI Hub) 사람 동작 영상 AI 데이터 28번 웨이트트레이닝 - 이미지에서 약 300장 추출\n",
        "* Supervisely를 통해 bbox 작업\n",
        "* 이미지 출처(https://aihub.or.kr/aidata/138/download)\n",
        "* 사용한 이미지와 작성한 bbox는 share folder에 첨부\n",
        "\n",
        "Object Detection에서 몇몇 사진의 경우, 사람이 아닌 의자를 탐지한 사진을 발견,추가 데이터 학습으로 사람을 추출하게끔 작업"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVfF7spUpDBB"
      },
      "source": [
        "# 추가 이미지 파일은 share_folder의 추가데이터/additional_data 폴더에 위치\n",
        "# additional_ann은 Supervisely에서 작업한 train용 bbox 정보가 담긴 json 파일들의 폴더\n",
        "ann_path = './data/Motion_Keypoint/additional_ann/'\n",
        "file_list = glob(ann_path + '*.json')\n",
        "file_list.sort()\n",
        "len(file_list)  # 308"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uLGdoWfpNVQ"
      },
      "source": [
        "json_file = file_list[0].split('/')[-1]\n",
        "img_file = json_file.split('.')[0] + '.jpg'\n",
        "print(json_file)\n",
        "print(img_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI_7NSYZpca6"
      },
      "source": [
        "# 추가 데이터를 집어넣을 빈 데이터프레임 생성\n",
        "additional_df = pd.DataFrame(columns=['images', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
        "\n",
        "# 빈 데이터프레임에 image 파일명 채우기\n",
        "file_name_list = []\n",
        "for i in range(len(file_list)):\n",
        "    file_name = file_list[i].split('/')[-1]\n",
        "    file_name = file_name.split('.json')[0]\n",
        "    file_name_list.append(file_name)\n",
        "    \n",
        "additional_df['images'] = file_name_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5RPydnVpj0B"
      },
      "source": [
        "# Supervisely에서 작업한 bbox는 xmin, ymin, xmax, ymax 형태\n",
        "# bbox들을 additional_df에 file_list 순서에 맞춰 넣어줌\n",
        "\n",
        "for i in range(len(file_list)):\n",
        "\n",
        "    with open(file_list[i], 'r') as f:\n",
        "        json_data = json.load(f)\n",
        "    \n",
        "    #json 파일의 points 추출\n",
        "    points = json_data['objects'][0]['points']['exterior']\n",
        "    xmin = points[0][0]\n",
        "    ymin = points[0][1]\n",
        "    xmax = points[1][0]\n",
        "    ymax = points[1][1]\n",
        "\n",
        "    coordinates = []\n",
        "    coordinates.append(xmin)\n",
        "    coordinates.append(ymin)\n",
        "    coordinates.append(xmax)\n",
        "    coordinates.append(ymax)\n",
        "    \n",
        "    additional_df.iloc[i,1:] = coordinates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb4XthGEqaS9"
      },
      "source": [
        "# additional_df 저장\n",
        "additional_df.to_csv('./data/Motion_Keypoint/additional_df.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AHBDz5Errbc"
      },
      "source": [
        "# train 데이터와 추가 데이터를 하나의 폴더안에 합쳐줍니다.\n",
        "%cd /content\n",
        "os.chdir('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/')\n",
        "\n",
        "src1 = \"train\"\n",
        "src2 = \"additional_data\"\n",
        "\n",
        "os.makedirs(root_dir +'/train_add')\n",
        "train_filename = os.listdir(src1)\n",
        "add_filename = os.listdir(src2)\n",
        "\n",
        "train_filename = [src+'/'+ name for name in train_filename]\n",
        "add_filename = [src+'/'+ name for name in add_filename]\n",
        "\n",
        "# copy & paste images\n",
        "for name in tqdm(train_filename):\n",
        "    shutil.copy(name, 'train_add')\n",
        "\n",
        "for name in tqdm(add_filename):\n",
        "    shutil.copy(name, 'train_add')\n",
        "\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLgpGgT4rE4r"
      },
      "source": [
        "## 1-2) train / valid / test set을 COCO format으로 변경"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AnngBdpYfwc"
      },
      "source": [
        "train용 파일, 추가 학습용 파일 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmaMd0TPrJN8"
      },
      "source": [
        "# 들어온 image를 json 파일형식으로 변환하는 코드\n",
        "# 폴더에서 jpg 형식의 파일들을 모두 읽은 다음 sort\n",
        "image_paths = glob(os.path.join('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/train','*.jpg'))\n",
        "image_paths.sort()\n",
        "len(image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy3abk0frRz1"
      },
      "source": [
        "#json 형식으로 담을 dict 생성\n",
        "file_data = OrderedDict()\n",
        "file_data['images'] = []\n",
        "\n",
        "# for문으로 mmdetection에서 사용할 file_data 형식으로 변형\n",
        "file_id = 0\n",
        "for i in tqdm(range(len(image_paths))):\n",
        "    img = Image.open(image_paths[i])\n",
        "    filename = image_paths[i].split('/')[-1]\n",
        "    img_dic = {'file_name': filename, 'height': img.size[1], 'width': img.size[0], 'id': file_id}\n",
        "    file_data['images'].append(img_dic)\n",
        "    file_id += 1\n",
        "\n",
        "# 3776이어야 함\n",
        "print(file_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxO8Iu7qrTzI"
      },
      "source": [
        "# Object_Detection용 추가 데이터\n",
        "add_image_paths = glob(os.path.join('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/additional_data','*.jpg'))\n",
        "add_image_paths.sort()\n",
        "print(len(add_image_paths))\n",
        "print(file_id)\n",
        "\n",
        "# 앞선 셀의 마지막 file_id는 img_dic에 들어가지 않았으므로\n",
        "# 계속 이어 받아도 무방\n",
        "for j in tqdm(range(len(add_image_paths))):\n",
        "    imge = Image.open(add_image_paths[j])\n",
        "    filenmae = add_image_paths[j].split('/')[-1]\n",
        "    img_dic = {'file_name': filename, 'height': img.size[1], 'width': img.size[0], 'id': file_id}\n",
        "    file_data['images'].append(img_dic)\n",
        "    file_id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq2V_IHXrVvl"
      },
      "source": [
        "# bbox 계산을 위해 csv 파일 read\n",
        "# df = pd.read_csv('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/train.csv')\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/train(0402).csv')\n",
        "df = df.sort_values(by=['image'], axis=0)\n",
        "df = df.reset_index(drop=True)\n",
        "print(len(df))\n",
        "df.tail(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azZre1KsrcZ9"
      },
      "source": [
        "# for문으로 mmdetection에서 사용할 file_data 형식으로 변형\n",
        "# file_data['annotations']은 -> {'segmentation': [], 'area':, 'category_id': label, 'bbox': [], image_id: file_id, 'iscrowd': 0, 'id': file_id} 형식으로 들어가야 함\n",
        "# COCO format에서 bbox는 [xmin, ymin, w, h] 형식임 -> [xmin, ymin, xmax-xmin, ymax-ymin]\n",
        "# image_paths의 경우 sort를 했고, df 또한 이름순으로 이미 정렬되어 있으므로 images의 id와 annotation의 image_id는 자연스레 mapping\n",
        "\n",
        "file_data['annotations'] = []\n",
        "\n",
        "image_id = 0\n",
        "annotation_id = 0\n",
        "for k in tqdm(range(len(image_paths))):\n",
        "    filename = df.iloc[k, 0]\n",
        "    xmin, ymin = min(df.iloc[k, 1::2]), min(df.iloc[k, 2::2])\n",
        "    xmax, ymax = max(df.iloc[k, 1::2]), max(df.iloc[k, 2::2])\n",
        "    w = xmax - xmin\n",
        "    h = ymax - ymin\n",
        "    bbox = [xmin, ymin, w, h]\n",
        "    area = float(w * h)\n",
        "    seg_dic = {'segmentation': [], 'area': area, 'category_id': 1, 'bbox': bbox, 'image_id': image_id, 'iscrowd': 0, 'id': annotation_id}\n",
        "    file_data['annotations'].append(seg_dic)\n",
        "    image_id += 1\n",
        "    annotation_id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVWODfD8rdt9"
      },
      "source": [
        "additional_df = pd.read_csv('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/additional_df.csv')\n",
        "additional_df = additional_df.sort_values(by=['images'], axis=0)\n",
        "additional_df = additional_df.reset_index(drop=True)\n",
        "print(len(additional_df))\n",
        "additional_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EldY75qgre87"
      },
      "source": [
        "# 둘다 3776\n",
        "print(image_id)\n",
        "print(annotation_id)\n",
        "\n",
        "# 앞선 셀의 마지막 image_id, annotation_id는 seg_dic 들어가지 않았으므로\n",
        "# 계속 이어 받아도 무방\n",
        "for l in tqdm(range(len(add_image_paths))):\n",
        "    xmin, ymin = additional_df.loc[l, 'xmin'], additional_df.loc[l, 'ymin']\n",
        "    xmax, ymax = additional_df.loc[l, 'xmax'], additional_df.loc[l, 'ymax']\n",
        "    xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)\n",
        "    w = xmax - xmin\n",
        "    h = ymax - ymin\n",
        "    bbox = [xmin, ymin, w, h]\n",
        "    area = float(w * h)\n",
        "    seg_dic = {'segmentation': [], 'area': area, 'category_id': 1, 'bbox': bbox, 'image_id': image_id, 'iscrowd': 0, 'id': annotation_id}\n",
        "    file_data['annotations'].append(seg_dic)\n",
        "    image_id += 1\n",
        "    annotation_id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOEGvz46rgA5"
      },
      "source": [
        "# mmdetection에서 사용할 categories 형식도 추가\n",
        "# 분류값은 사람뿐이므로 person만 추가\n",
        "file_data['categories'] = [{\"id\": 1, \"name\": \"person\"}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFIYIEGKrhLq"
      },
      "source": [
        "# json 파일로 저장\n",
        "with open('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/train_mmdetection_add.json', 'w', encoding='utf-8') as make_file:\n",
        "    json.dump(file_data, make_file, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxAjiTusYlF4"
      },
      "source": [
        "validation용 파일 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTOXL_YrrlLv"
      },
      "source": [
        "image_paths = glob(os.path.join('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/val','*.jpg'))\n",
        "image_paths.sort()\n",
        "len(image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KUyg0zbrmyq"
      },
      "source": [
        "#json 형식으로 담을 dict 생성\n",
        "file_data = OrderedDict()\n",
        "file_data['images'] = []\n",
        "\n",
        "# for문으로 mmdetection에서 사용할 file_data 형식으로 변형\n",
        "file_id = 0\n",
        "for i in tqdm(range(len(image_paths))):\n",
        "    img = Image.open(image_paths[i])\n",
        "    filename = image_paths[i].split('/')[-1]\n",
        "    img_dic = {'file_name': filename, 'height': img.size[1], 'width': img.size[0], 'id': file_id}\n",
        "    file_data['images'].append(img_dic)\n",
        "    file_id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVghEJnGrnyG"
      },
      "source": [
        "# bbox 계산을 위해 csv 파일 read\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/valid(0402).csv')\n",
        "df = df.sort_values(by=['image'], axis=0)\n",
        "df = df.reset_index(drop=True)\n",
        "print(len(df))\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i1Tu8VUro8j"
      },
      "source": [
        "# for문으로 mmdetection에서 사용할 file_data 형식으로 변형\n",
        "# file_data['annotations']은 -> {'segmentation': [], 'area':, 'category_id': label, 'bbox': [], image_id: file_id, 'iscrowd': 0, 'id': file_id} 형식으로 들어가야 함\n",
        "# COCO format에서 bbox는 [xmin, ymin, w, h] 형식임 -> [xmin, ymin, xmax-xmin, ymax-ymin]\n",
        "# image_paths의 경우 sort를 했고, df 또한 이름순으로 이미 정렬되어 있으므로 images의 id와 annotation의 image_id는 자연스레 mapping\n",
        "\n",
        "file_data['annotations'] = []\n",
        "\n",
        "image_id = 0\n",
        "annotation_id = 0\n",
        "for k in tqdm(range(len(image_paths))):\n",
        "    filename = df.iloc[k, 0]\n",
        "    xmin, ymin = min(df.iloc[k, 1::2]), min(df.iloc[k, 2::2])\n",
        "    xmax, ymax = max(df.iloc[k, 1::2]), max(df.iloc[k, 2::2])\n",
        "    w = xmax - xmin\n",
        "    h = ymax - ymin\n",
        "    bbox = [xmin, ymin, w, h]\n",
        "    area = float(w * h)\n",
        "    seg_dic = {'segmentation': [], 'area': area, 'category_id': 1, 'bbox': bbox, 'image_id': image_id, 'iscrowd': 0, 'id': annotation_id}\n",
        "    file_data['annotations'].append(seg_dic)\n",
        "    image_id += 1\n",
        "    annotation_id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jCAJN81rqUx"
      },
      "source": [
        "# mmdetection에서 사용할 categories 형식도 추가\n",
        "# 분류값은 사람뿐이므로 person만 추가\n",
        "file_data['categories'] = [{\"id\": 1, \"name\": \"person\"}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xtrClIrrrqx"
      },
      "source": [
        "# json 파일로 저장\n",
        "with open('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/valid_mmdetection.json', 'w', encoding='utf-8') as make_file:\n",
        "    json.dump(file_data, make_file, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVYH2JtDGU3h"
      },
      "source": [
        "Test용 파일 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzQMw-yUta7I"
      },
      "source": [
        "image_paths = glob(os.path.join('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/test_imgs','*.jpg'))\n",
        "image_paths.sort()\n",
        "len(image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4WgONKQtfdE"
      },
      "source": [
        "#train_json 형식으로 담을 dict 생성\n",
        "file_data = OrderedDict()\n",
        "file_data['images'] = []\n",
        "\n",
        "# for문으로 mmdetection에서 사용할 file_data 형식으로 변형\n",
        "file_id = 0\n",
        "for i in tqdm(range(len(image_paths))):\n",
        "    img = Image.open(image_paths[i])\n",
        "    filename = image_paths[i].split('/')[-1]\n",
        "    img_dic = {'file_name': filename, 'height': img.size[1], 'width': img.size[0], 'id': file_id}\n",
        "    file_data['images'].append(img_dic)\n",
        "    file_id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjJHllgZthro"
      },
      "source": [
        "# mmdetection에서 사용할 categories 형식도 추가\n",
        "# 분류값은 사람뿐이므로 person만 추가\n",
        "file_data['categories'] = [{\"id\": 1, \"name\": \"person\"}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFUs7bpxtigy"
      },
      "source": [
        "# json 파일로 저장\n",
        "with open('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/test_mmdetection.json', 'w', encoding='utf-8') as make_file:\n",
        "    json.dump(file_data, make_file, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRI-zVEwEyzT"
      },
      "source": [
        "## 1-3) DetectoRS 모델 학습(MMdetection)\n",
        "* ResNeXt-101-64x4d, multi-scale을 시도했으나 의의로 Resnet-50의 성과가 더 좋게 나왔음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTdfkLOItj55"
      },
      "source": [
        "# 이미 사전에 특정 위치에 설치한 관계로 경로 이동\n",
        "# Colab은 도커형식으로 특정 위치로 이동 후 mmdetection을 clone하지 않으면\n",
        "# 해당 폴더는 연결이 끊기는 순간 사라짐\n",
        "%cd drive/MyDrive\n",
        "\n",
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D9idiq_tlic"
      },
      "source": [
        "# Colab 상에서의 mmdetection 환경설정\n",
        "# Colab Pro에서는 CUDA 11.0 버젼이지만 mmdetection installation docs 따라 설치하겠습니다.\n",
        "\n",
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install mmcv-full thus we could use CUDA operators\n",
        "!pip install mmcv-full==1.2.7\n",
        "\n",
        "# Install mmdetection\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "\n",
        "!pip install -e .\n",
        "\n",
        "# install Pillow 7.0.0 back in order to avoid bug in colab\n",
        "!pip install Pillow==7.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il7qOUjVtmiR"
      },
      "source": [
        "# 학습 진행\n",
        "# 학습을 위한 configs 파일들은 share folder에 첨부. mmdetection folder 내 같은 경로에 넣어주면 됩니다.\n",
        "# Colab에서 사용시 /usr/local/lib/python3.7/dist-packages/mmcv/runner/epoch_based_runner.py 해당 경로의\n",
        "# 135번째 줄 save_checkpoint함수의 create_symlink=False로 바꿔줘야 latest.pth 파일 오류 생성 x\n",
        "\n",
        "    # img_prefix=data_root + 'train_add'에서 train_add는 train image와 추가데이터 image가 함께 있는 폴더입니다.\n",
        "# mmdet/datasets/coco.py 역시 수정 파일로 share folder에 첨부\n",
        "\n",
        "!python tools/train.py configs/detectors/detectors_cascade_rcnn_r50_1x_coco_0329.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYr2gNK9ATzK"
      },
      "source": [
        "# test 진행\n",
        "!python tools/test.py configs/detectors/detectors_cascade_rcnn_r50_1x_coco_0329.py work_dirs/detectors_cascade_rcnn_r50_1x_coco_0329/epoch_20.pth --format-only --eval-options \"jsonfile_prefix=./detectors_epoch_20\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn6o3IbWaDd1"
      },
      "source": [
        "## 2-1) train / valid / test set을 Keypoint Detection을 위한 형태로 변경\n",
        "annotation을 지정해 줘야 하기 때문에 변경을 한번 더 수행합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzMlXQQTc84I"
      },
      "source": [
        "train set 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF27PY3zbY0X"
      },
      "source": [
        "# mmdetection용 json파일 생성 방식과 거의 동일합니다.\n",
        "# Keypoint Detection에는 추가 데이터를 사용하지 않습니다.\n",
        "%cd /content\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint')\n",
        "image_paths = glob(os.path.join('train','*.jpg'))\n",
        "image_paths.sort()\n",
        "len(image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tjX2wqrbG3y"
      },
      "source": [
        "# COCO images 처리\n",
        "file_data = OrderedDict()\n",
        "file_data['images'] = []\n",
        "\n",
        "id = 0\n",
        "for i in tqdm(range(len(image_paths))):\n",
        "    img = Image.open(image_paths[i])\n",
        "    filename = image_paths[i].split('/')[-1]\n",
        "    file_id = filename.split('.')[0]\n",
        "    img_dic = {'file_name': filename, 'height': img.size[1], 'width': img.size[0], 'id': id}\n",
        "    file_data['images'].append(img_dic)\n",
        "    id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya3rnO7JbHBA"
      },
      "source": [
        "# COCO annotations 처리\n",
        "train = pd.read_csv('./train.csv')\n",
        "train.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MIWM5TGcMsk"
      },
      "source": [
        "# annotations의 전체 keypoints 생성\n",
        "# COCO format은 keypoint 지정에 v축을 요구\n",
        "# 사진을 다 확인할 수 없는 관계로 v를 2로 설정\n",
        "# 사진을 다 확인할 수 없는 관계로 v를 2로 설정\n",
        "\n",
        "nose_xy = train.iloc[:, 1:3].values\n",
        "properties = np.array([[2]]*len(train))\n",
        "keypoints = np.concatenate((nose_xy, properties), axis=1)\n",
        "\n",
        "for i in tqdm(range(23)):\n",
        "    xy = train.iloc[:, 3+(2*i):5+(2*i)].values\n",
        "    v = np.array([[2]]*len(train))\n",
        "    keypoint = np.concatenate((xy,v), axis=1)\n",
        "    keypoints = np.concatenate((keypoints, keypoint), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z82IIyuCcPBQ"
      },
      "source": [
        "file_data['annotations'] = []\n",
        "id = 0\n",
        "\n",
        "## COCO format은 keypoint 지정에 v축을 요구\n",
        "## 사진을 다 확인할 수 없는 관계로 v를 2로 설정\n",
        "for i in tqdm(range(len(train))):\n",
        "    file_name = train.loc[i].image\n",
        "    file_id = file_name.split('.')[0]\n",
        "    key = keypoints[i]\n",
        "    xmin = train.iloc[i, 1::2].values.min()\n",
        "    xmax = train.iloc[i, 1::2].values.max()\n",
        "    w = xmax - xmin\n",
        "    ymin = train.iloc[i, 2::2].values.min()\n",
        "    ymax = train.iloc[i, 2::2].values.max()\n",
        "    h = ymax - ymin\n",
        "    bbox = [xmin, ymin, w,h]\n",
        "    area = w * h\n",
        "    annotation_dic = {'segmentation': [], 'keypoints': key.tolist(), 'num_keypoints': 24, 'area': area, 'iscrowd': 0, 'image_id': id, 'bbox': bbox, 'category_id': 1, 'id': id}\n",
        "    file_data['annotations'].append(annotation_dic)\n",
        "    id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLLVzkdZcR7H"
      },
      "source": [
        "file_data['categories'] = [{'id': 1, \n",
        "                            'name': 'person',\n",
        "                            \"keypoints\": [\"nose\",\"left_eye\",\"right_eye\",\"left_ear\",\"right_ear\",\n",
        "                                          \"left_shoulder\",\"right_shoulder\",\"left_elbow\",\"right_elbow\",\n",
        "                                          \"left_wrist\",\"right_wrist\",\"left_hip\",\"right_hip\",\n",
        "                                          \"left_knee\",\"right_knee\",\"left_ankle\",\"right_ankle\",\n",
        "                                          \"neck\", \"left_palm\", \"right_palm\", \"spine2(back)\", \"spine1(back)\", \"left_instep\", \"right_instep\"],\n",
        "                            \"skeleton\": [[16,14],[14,12],[17,15],[15,13],[12,13],[6,12],[7,13],[18,6],[18,7],\n",
        "                                         [6,8],[7,9],[8,10],[9,11],[2,3],[1,2],[1,3],[2,4],[3,5],[4,6],[5,7],\n",
        "                                         [1,18], [18,21], [21,22], [22,12], [22,13], [23,16], [24,17]]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deColzIzc5V-"
      },
      "source": [
        "with open('./train_ann.json', 'w', encoding='utf-8') as make_file:\n",
        "    json.dump(file_data, make_file, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDr6g1ykdFZe"
      },
      "source": [
        "valid set 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar71it3EdFGl"
      },
      "source": [
        "# mmdetection용 json파일 생성 방식과 거의 동일합니다.\n",
        "# Keypoint Detection에는 추가 데이터를 사용하지 않습니다.\n",
        "%cd /content\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint')\n",
        "image_paths = glob(os.path.join('val','*.jpg'))\n",
        "image_paths.sort()\n",
        "len(image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s27ureddJa0"
      },
      "source": [
        "# COCO images 처리\n",
        "file_data = OrderedDict()\n",
        "file_data['images'] = []\n",
        "\n",
        "id = 0\n",
        "for i in tqdm(range(len(image_paths))):\n",
        "    img = Image.open(image_paths[i])\n",
        "    filename = image_paths[i].split('/')[-1]\n",
        "    file_id = filename.split('.')[0]\n",
        "    img_dic = {'file_name': filename, 'height': img.size[1], 'width': img.size[0], 'id': id}\n",
        "    file_data['images'].append(img_dic)\n",
        "    id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tkySHh4dQWH"
      },
      "source": [
        "# COCO annotations 처리\n",
        "valid = pd.read_csv('./valid.csv')\n",
        "valid.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyKEEcmtdXUS"
      },
      "source": [
        "# annotations의 전체 keypoints 생성\n",
        "# COCO format은 keypoint 지정에 v축을 요구\n",
        "# 사진을 다 확인할 수 없는 관계로 v를 2로 설정\n",
        "# 사진을 다 확인할 수 없는 관계로 v를 2로 설정\n",
        "\n",
        "nose_xy = valid.iloc[:, 1:3].values\n",
        "properties = np.array([[2]]*len(valid))\n",
        "keypoints = np.concatenate((nose_xy, properties), axis=1)\n",
        "\n",
        "for i in tqdm(range(23)):\n",
        "    xy = valid.iloc[:, 3+(2*i):5+(2*i)].values\n",
        "    v = np.array([[2]]*len(valid))\n",
        "    keypoint = np.concatenate((xy,v), axis=1)\n",
        "    keypoints = np.concatenate((keypoints, keypoint), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwz4NmsJdb-G"
      },
      "source": [
        "file_data['annotations'] = []\n",
        "id = 0\n",
        "\n",
        "## COCO format은 keypoint 지정에 v축을 요구\n",
        "## 사진을 다 확인할 수 없는 관계로 v를 2로 설정\n",
        "for i in tqdm(range(len(valid))):\n",
        "    file_name = valid.loc[i].image\n",
        "    file_id = file_name.split('.')[0]\n",
        "    key = keypoints[i]\n",
        "    xmin = valid.iloc[i, 1::2].values.min()\n",
        "    xmax = valid.iloc[i, 1::2].values.max()\n",
        "    w = xmax - xmin\n",
        "    ymin = valid.iloc[i, 2::2].values.min()\n",
        "    ymax = valid.iloc[i, 2::2].values.max()\n",
        "    h = ymax - ymin\n",
        "    bbox = [xmin, ymin, w,h]\n",
        "    area = w * h\n",
        "    annotation_dic = {'segmentation': [], 'keypoints': key.tolist(), 'num_keypoints': 24, 'area': area, 'iscrowd': 0, 'image_id': id, 'bbox': bbox, 'category_id': 1, 'id': id}\n",
        "    file_data['annotations'].append(annotation_dic)\n",
        "    id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJiKxRqWddsh"
      },
      "source": [
        "file_data['categories'] = [{'id': 1, \n",
        "                            'name': 'person',\n",
        "                            \"keypoints\": [\"nose\",\"left_eye\",\"right_eye\",\"left_ear\",\"right_ear\",\n",
        "                                          \"left_shoulder\",\"right_shoulder\",\"left_elbow\",\"right_elbow\",\n",
        "                                          \"left_wrist\",\"right_wrist\",\"left_hip\",\"right_hip\",\n",
        "                                          \"left_knee\",\"right_knee\",\"left_ankle\",\"right_ankle\",\n",
        "                                          \"neck\", \"left_palm\", \"right_palm\", \"spine2(back)\", \"spine1(back)\", \"left_instep\", \"right_instep\"],\n",
        "                            \"skeleton\": [[16,14],[14,12],[17,15],[15,13],[12,13],[6,12],[7,13],[18,6],[18,7],\n",
        "                                         [6,8],[7,9],[8,10],[9,11],[2,3],[1,2],[1,3],[2,4],[3,5],[4,6],[5,7],\n",
        "                                         [1,18], [18,21], [21,22], [22,12], [22,13], [23,16], [24,17]]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e33n6ZQWdfK3"
      },
      "source": [
        "with open('./valid_ann.json', 'w', encoding='utf-8') as make_file:\n",
        "    json.dump(file_data, make_file, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_03K1T7Ea_Mc"
      },
      "source": [
        "test set 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQJoyg8IWORe"
      },
      "source": [
        "# MMpose의 ann_file은 id를 file_name으로 읽기 때문에 위에서 만든 test_mmdetection.json의\n",
        "# id값만 file_name으로 맞춰서 변경\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/test_mmdetection.json\"\n",
        "with open(file_path, 'r') as f:\n",
        "    test_mmdetection = json.load(f)\n",
        "\n",
        "for images in test_mmdetection['images']:\n",
        "    images['id'] = images['file_name']\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/test_0331.json', 'w', encoding='utf-8') as make_file:\n",
        "    json.dump(test_mmdetection, make_file, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX1E6vdLoTs3"
      },
      "source": [
        "추가적으로 data_cfg 중 bbox_file에 넣어줄 형식도 필요합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u_hELefo0QO"
      },
      "source": [
        "train에 쓰일 data_cfg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZZDa_dTo5re"
      },
      "source": [
        "# train과 개수만 맞으면 되기 때문에 위에서 만든 train_ann을 임의로 불러옵니다.\n",
        "# \"image_id\": \"001-1-1-01-Z17_A-0000001.jpg\" 아래와 같이 파일명으로 지정해야 bbox_file을 읽는데 오류 x\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/train_ann.json\"\n",
        "with open(file_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "file_data = []\n",
        "# train의 경우, score값은 1로 지정\n",
        "for i in tqdm(range(len(data['images']))):\n",
        "    dic = {'bbox': data['annotations'][i]['bbox'], 'category_id': 1, 'image_id': data['annotations'][i]['image_id'], 'score': 1.0}\n",
        "    file_data.append(dic)\n",
        "\n",
        "for i in tqdm(range(len(file_data))):\n",
        "    file_data[i]['image_id'] = file_data[i]['image_id'] + '.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyifGjATo8Za"
      },
      "source": [
        "# 파일명\n",
        "with open('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/train_mmpose_bbox.json', 'w', encoding='utf-8') as make_file:\n",
        "    json.dump(file_data, make_file, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tozNFo8lo6iE"
      },
      "source": [
        "test에 쓰일 data_cfg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX5GOjikpiji"
      },
      "source": [
        "# test에 쓰일 data_cfg는 Object Detection으로 생성된 bbox로 bbox_file로 생성\n",
        "# \"image_id\": \"001-1-1-01-Z17_A-0000001.jpg\" 아래와 같이 파일명으로 지정해야 bbox_file을 읽는데 오류 x\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/mmdetection/detectors_epoch_20.bbox.json\"\n",
        "with open(file_path, 'r') as f:\n",
        "    bbox = json.load(f)\n",
        "\n",
        "for images in bbox['bbox']:\n",
        "    images['id'] = images['file_name']\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/train_mmpose_bbox.json', 'w', encoding='utf-8') as make_file:\n",
        "    json.dump(bbox, make_file, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oINS5c4VN66F"
      },
      "source": [
        "## 2-2) DarkPose(MMpose)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG8qI3HPOAAZ"
      },
      "source": [
        "# 이미 사전에 특정 위치에 설치한 관계로 경로 이동\n",
        "# Colab은 도커형식으로 특정 위치로 이동 후 mmpose를 clone하지 않으면\n",
        "# 해당 폴더는 연결이 끊기는 순간 사라짐\n",
        "%cd /content\n",
        "%cd drive/MyDrive\n",
        "\n",
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF38Ys6WN-Ff"
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# # install mmcv-full thus we could use CUDA operators\n",
        "!pip install mmcv-full==1.2.7\n",
        "\n",
        "# # Install mmdetection\n",
        "# !rm -rf mmpose\n",
        "!git clone https://github.com/open-mmlab/mmpose.git\n",
        "%cd mmpose\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e .\n",
        "\n",
        "# install Pillow 7.0.0 back in order to avoid bug in colab\n",
        "!pip install Pillow==7.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBzNkSFfOM5a"
      },
      "source": [
        "# mmpose의 경우, \n",
        "# requirements.txt의 numpy 1.19.5버전이 오류를 발생시키는 관계로\n",
        "# numpy를 1.20.0 버전으로 업데이트\n",
        "!pip install numpy==1.20.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBBvCW0-U6R6"
      },
      "source": [
        "# Keypoint Detection 학습\n",
        "# 학습을 위한 configs 파일들은 share folder에 첨부. mmpose folder 내 같은 경로에 넣어주면 됩니다.\n",
        "# mmdet/datasets/datasets/top_down/topdown_coco_dataset.py 역시 수정 파일로 share folder에 첨부\n",
        "# Colab에서 사용시 /usr/local/lib/python3.7/dist-packages/mmcv/runner/epoch_based_runner.py 해당 경로의\n",
        "# 135번째 줄 save_checkpoint함수의 create_symlink=False로 바꿔줘야 latest.pth 파일 오류 생성 x\n",
        "\n",
        "# --work-dir 경로에 학습한 모델들이 저장\n",
        "!python tools/train.py configs/top_down/darkpose/coco/hrnet_w48_coco_384x288_dark.py --work-dir work_dirs/darkpose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXh1IkTKU-Cj"
      },
      "source": [
        "# test할 경우에는\n",
        "# hrnet_w48_coco_384x288_dark.py의 data_cfg의 'bbox_file'을 위에서 만든 train_mmpose_bbox.json으로 바꿔줘야 함\n",
        "# share folder에 올린 hrnet_w48_coco_384x288_dark.py에 주석처리 해둠\n",
        "# -out 명령어로 파일명 지정\n",
        "!python tools/test.py configs/top_down/darkpose/coco/hrnet_w48_coco_384x288_dark.py work_dirs/darkpose/epoch_205.pth --out 'darkpose.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM53uFVzVRgR"
      },
      "source": [
        "## Make Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I99vKPdjVJuE"
      },
      "source": [
        "# DakrPose가 예측한 json 파일을 불러옵니다.\n",
        "\n",
        "file_path = \"./darkpose.json\"\n",
        "with open(file_path, 'r') as f:\n",
        "    result = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKafTb7AVKYZ"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRa1YLihVMuJ"
      },
      "source": [
        "pred = []\n",
        "for output in tqdm(result):\n",
        "    row = []\n",
        "    image_name = output['image_paths'][0].split('/')[-1]\n",
        "    row.append(image_name)\n",
        "    for i in range(24):\n",
        "        row.append(output['preds'][0][i][0])\n",
        "        row.append(output['preds'][0][i][1])\n",
        "    pred.append(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyM8F6EtVOH-"
      },
      "source": [
        "column = submission.columns\n",
        "submission = pd.DataFrame.from_records(pred, columns=column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jYl_8iZVOzA"
      },
      "source": [
        "submission.to_csv('/content/drive/MyDrive/Colab/Dacon/Motion_Keypoint/darkpose.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}